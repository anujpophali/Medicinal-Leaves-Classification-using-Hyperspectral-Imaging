{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7661598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for SVM is: 99.76019184652279\n",
      "Confusion Matrix:\n",
      "[[76  0  0  0  0  0  0]\n",
      " [ 0 57  0  0  0  0  0]\n",
      " [ 0  0 78  0  0  0  0]\n",
      " [ 0  0  0 69  0  0  0]\n",
      " [ 0  0  0  0 31  0  0]\n",
      " [ 0  1  0  0  0 62  0]\n",
      " [ 0  0  0  0  0  0 43]]\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle \n",
    "\n",
    "\n",
    "# Importing the dataset from the sklearn library into a local variable called dataset\n",
    "df = pd.read_excel(\"train.xlsx\")\n",
    "\n",
    "# Extract the hyperspectral data (excluding the last column) and labels (last column)\n",
    "hyperspectral_data = df.iloc[:, :-1].values\n",
    "labels = df.iloc[:, -1].values\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "X = hyperspectral_data\n",
    "Y = encoded_labels\n",
    "\n",
    "# Splitting the data test into train 70% and test 30%.\n",
    "# x_train, y_train are training data and labels respectively \n",
    "# x_test, y_test are testing data and labels respectively \n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=4)\n",
    "\n",
    "# Making the SVM Classifer\n",
    "Classifier = SVC(kernel=\"linear\")\n",
    "\n",
    "# Training the model on the training data and labels\n",
    "Classifier.fit(x_train, y_train)\n",
    "\n",
    "# Using the model to predict the labels of the test data\n",
    "y_pred = Classifier.predict(x_test)\n",
    "\n",
    "# Evaluating the accuracy of the model using the sklearn functions\n",
    "accuracy = accuracy_score(y_test,y_pred)*100\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "# Printing the results\n",
    "print(\"Accuracy for SVM is:\",accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "\n",
    "# Step 10: Save the trained classifier for future use\n",
    "pickle.dump(Classifier, open(\"cls.sav\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8459b7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels1 :  ['Dry_Pudina' 'Dry_Pudina' 'Dry_Pudina' 'Dry_Pudina' 'Dry_Pudina'\n",
      " 'Dry_Pudina' 'Dry_Pudina' 'Dry_Pudina' 'Dry_Pudina' 'Dry_Pudina'\n",
      " 'Dry_Pudina' 'Dry_Pudina' 'Dry_Pudina' 'Dry_Pudina' 'Dry_Pudina'\n",
      " 'Dry_Pudina' 'Fresh_Pudina' 'Fresh_Pudina' 'Fresh_Pudina' 'Fresh_Pudina'\n",
      " 'Fresh_Pudina' 'Fresh_Pudina' 'Fresh_Pudina' 'Fresh_Pudina'\n",
      " 'Fresh_Pudina' 'Fresh_Pudina' 'Fresh_Pudina' 'Fresh_Pudina'\n",
      " 'Fresh_Pudina' 'Fresh_Pudina' 'Fresh_Pudina' 'Fresh_Pudina'\n",
      " 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Very_Dry_Pudina'\n",
      " 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Very_Dry_Pudina'\n",
      " 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Very_Dry_Pudina'\n",
      " 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Very_Dry_Pudina'\n",
      " 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Dry_Tulsi'\n",
      " 'Dry_Tulsi' 'Dry_Tulsi' 'Dry_Tulsi' 'Dry_Tulsi' 'Dry_Tulsi' 'Dry_Tulsi'\n",
      " 'Dry_Tulsi' 'Dry_Tulsi' 'Dry_Tulsi' 'Dry_Tulsi' 'Dry_Tulsi' 'Dry_Tulsi'\n",
      " 'Dry_Tulsi' 'Dry_Tulsi' 'Dry_Tulsi' 'Fresh_Tulsi' 'Fresh_Tulsi'\n",
      " 'Fresh_Tulsi' 'Fresh_Tulsi' 'Fresh_Tulsi' 'Fresh_Tulsi' 'Fresh_Tulsi'\n",
      " 'Fresh_Tulsi' 'Fresh_Tulsi' 'Fresh_Tulsi' 'Fresh_Tulsi' 'Fresh_Tulsi'\n",
      " 'Fresh_Tulsi' 'Fresh_Tulsi' 'Fresh_Tulsi' 'Fresh_Tulsi' 'Fresh_Neem'\n",
      " 'Fresh_Neem' 'Fresh_Neem' 'Fresh_Neem' 'Fresh_Neem' 'Fresh_Neem'\n",
      " 'Fresh_Neem' 'Fresh_Neem' 'Fresh_Neem' 'Fresh_Neem' 'Fresh_Neem'\n",
      " 'Fresh_Neem' 'Dry_Neem' 'Dry_Neem' 'Dry_Neem' 'Dry_Neem' 'Dry_Neem'\n",
      " 'Dry_Neem' 'Dry_Neem' 'Dry_Neem' 'Dry_Neem' 'Dry_Neem' 'Dry_Neem'\n",
      " 'Dry_Neem']\n",
      "Predictions: ['Dry_Pudina' 'Dry_Pudina' 'Dry_Pudina' 'Dry_Pudina' 'Dry_Pudina'\n",
      " 'Dry_Pudina' 'Dry_Pudina' 'Dry_Pudina' 'Dry_Pudina' 'Dry_Pudina'\n",
      " 'Dry_Pudina' 'Dry_Pudina' 'Dry_Pudina' 'Dry_Pudina' 'Dry_Pudina'\n",
      " 'Dry_Pudina' 'Fresh_Pudina' 'Fresh_Pudina' 'Fresh_Pudina' 'Fresh_Pudina'\n",
      " 'Fresh_Pudina' 'Fresh_Pudina' 'Fresh_Pudina' 'Fresh_Pudina'\n",
      " 'Fresh_Pudina' 'Fresh_Pudina' 'Fresh_Pudina' 'Fresh_Pudina'\n",
      " 'Fresh_Pudina' 'Fresh_Pudina' 'Fresh_Pudina' 'Fresh_Pudina'\n",
      " 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Very_Dry_Pudina'\n",
      " 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Very_Dry_Pudina'\n",
      " 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Very_Dry_Pudina'\n",
      " 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Very_Dry_Pudina'\n",
      " 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Very_Dry_Pudina' 'Dry_Tulsi'\n",
      " 'Dry_Tulsi' 'Dry_Tulsi' 'Dry_Tulsi' 'Dry_Tulsi' 'Dry_Tulsi' 'Dry_Tulsi'\n",
      " 'Dry_Tulsi' 'Dry_Tulsi' 'Dry_Tulsi' 'Dry_Tulsi' 'Dry_Tulsi' 'Dry_Tulsi'\n",
      " 'Dry_Tulsi' 'Dry_Tulsi' 'Dry_Tulsi' 'Fresh_Tulsi' 'Fresh_Tulsi'\n",
      " 'Fresh_Tulsi' 'Fresh_Tulsi' 'Fresh_Tulsi' 'Fresh_Tulsi' 'Fresh_Tulsi'\n",
      " 'Fresh_Tulsi' 'Fresh_Tulsi' 'Fresh_Tulsi' 'Fresh_Tulsi' 'Fresh_Tulsi'\n",
      " 'Fresh_Tulsi' 'Fresh_Tulsi' 'Fresh_Tulsi' 'Fresh_Tulsi' 'Fresh_Neem'\n",
      " 'Fresh_Neem' 'Fresh_Neem' 'Fresh_Neem' 'Fresh_Neem' 'Fresh_Neem'\n",
      " 'Fresh_Neem' 'Fresh_Neem' 'Fresh_Neem' 'Fresh_Neem' 'Fresh_Neem'\n",
      " 'Fresh_Neem' 'Dry_Neem' 'Dry_Neem' 'Dry_Neem' 'Dry_Neem' 'Dry_Neem'\n",
      " 'Dry_Neem' 'Dry_Neem' 'Dry_Neem' 'Dry_Neem' 'Dry_Neem' 'Dry_Neem'\n",
      " 'Dry_Neem']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "classifier = pickle.load(open(\"cls.sav\", \"rb\"))\n",
    "\n",
    "# Importing the dataset from the sklearn library into a local variable called dataset\n",
    "df1 = pd.read_excel(\"test.xlsx\")\n",
    "\n",
    "# Extract the hyperspectral data (excluding the last column) and labels (last column)\n",
    "hyperspectral_data1 = df1.iloc[:, :-1].values\n",
    "labels1 = df1.iloc[:, -1].values\n",
    "print(\"labels1 : \",labels1)\n",
    "\n",
    "new_pred = classifier.predict(hyperspectral_data1)\n",
    "decoded_predictions = label_encoder.inverse_transform(new_pred)\n",
    "print(\"Predictions:\", decoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e109f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
